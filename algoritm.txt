In perception.py at first, we are going to determine the position of the world using data.pose.orientation of each x,y,z,w. When the variable cam_str(which was initially assigned to "wait") gets published, the tf is published too. There are cases where the tomatoes get covered by the leaves, resulting one half of the tomato getting displayed, and the later half being identified as another object inspite of being part of the same thing. To omit such mishappenings, function isTooclose() is defined which stores each object in a list and merges them if they are in closer proximity. It gets the euler angles and joint values with respect to each world frame and publishes them using tf. The detection of tomatoes using opencv is being implemented. It has a counter variable, each time it detects a red tomato, the counter gets incremented by 1 and this is being printed to bring the number of detected tomatoes in the frame.
The motion2.py is coded with various attributes like laser_callback, odom_callbac,motion_callback. The global variable motion_str initally set to "wait" and stays in dormancy until and unless it gets pose values. There are three loops which gets executed sequentially when they get the pose values or the angle. When it detects each tomato, the cam_control publishes "pluck" and prints "stopped". When the angles dont effectuate the requirements, they are put to rate.sleep. And various angles get printed when each angle condition is satisfied.
The sjcam.py code holds the detection of aruco markers. The centre_x and centre_y along with the aruco_dimension(the values which were already provided) along with their formula which can be used to calculate the world position and publish tf. When the length of the corner is greater than zero, the detection of aruco markers start.A for loop is started which extracts corners which are always returned in top-left, top-right, bottom-right, and bottom-left order.
arm.py which controls the movement of the arm. The joint angle values are taken as a parameterised inputs and appended to a list after converting it into degrees and radians in the degree(), radian() functions respectively. The odom_callback() function ascertains the angle and pose through data.pose.pose.orientation in each x,y,z,w coordinate systems. Thus we calculate each rectangular coordinates and joint values which helps the arm to go to the goal position where the tomato is, from home position and takes a turn of 180 degrees. The code can be improvised in many ways, but due to lack of time and inadequate materials provided, it became challenging for us to work on it.

